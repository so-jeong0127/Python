{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 숙제 \n",
    "- iris.csv 데이터를 로딩한 다음\n",
    "- 분류망을 구성하시오.\n",
    "- parameter tuning을 구현하시오.(pipeline 사용도 함께)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iris 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width petal_length petal_width species\n",
       "1           6.4          2.8          5.6         2.2       2\n",
       "2           5.0          2.3          3.3           1       1\n",
       "3           4.9          2.5          4.5         1.7       2\n",
       "4           4.9          3.1          1.5         0.1       0\n",
       "5           5.7          3.8          1.7         0.3       0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = pd.read_csv('iris.csv', names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"])\n",
    "iris = iris.iloc[1:,:]\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, test 데이터로 나눠주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = iris.iloc[:, 0:4]\n",
    "Y = iris.iloc[:, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원핫인코딩으로 변환해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "# np_utils.to_categorical() 로 원핫인코딩으로 변환\n",
    "y = np_utils.to_categorical(Y, 3)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2\n",
       "2    1\n",
       "3    2\n",
       "4    0\n",
       "5    0\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 가중치 초기화 & activation함수 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_mode =['uniform', 'lecun_uniform', 'normal', 'zero' ,'glorot_normal' ,'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "activation = ['softmax', 'softplus', 'softsign',' relu','tanh','sigmoid', 'hard_sigmoid','linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(init_mode, activation):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim = 4, activation=activation))\n",
    "    model.add(Dense(3, kernel_initializer = init_mode, activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "model = KerasClassifier(build_fn = create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스코어: 0.480000 사용한 조합: {'activation': 'tanh', 'init_mode': 'he_normal'}\n",
      "0.306667 (0.057349) with : {'activation': 'softmax', 'init_mode': 'uniform'}\n",
      "0.366667 (0.165999) with : {'activation': 'softmax', 'init_mode': 'lecun_uniform'}\n",
      "0.293333 (0.082731) with : {'activation': 'softmax', 'init_mode': 'normal'}\n",
      "0.373333 (0.154056) with : {'activation': 'softmax', 'init_mode': 'zero'}\n",
      "0.373333 (0.090431) with : {'activation': 'softmax', 'init_mode': 'glorot_normal'}\n",
      "0.226667 (0.138884) with : {'activation': 'softmax', 'init_mode': 'glorot_uniform'}\n",
      "0.226667 (0.118134) with : {'activation': 'softmax', 'init_mode': 'he_normal'}\n",
      "0.293333 (0.212289) with : {'activation': 'softmax', 'init_mode': 'he_uniform'}\n",
      "0.280000 (0.033993) with : {'activation': 'softplus', 'init_mode': 'uniform'}\n",
      "0.353333 (0.093333) with : {'activation': 'softplus', 'init_mode': 'lecun_uniform'}\n",
      "0.280000 (0.074833) with : {'activation': 'softplus', 'init_mode': 'normal'}\n",
      "0.253333 (0.054160) with : {'activation': 'softplus', 'init_mode': 'zero'}\n",
      "0.266667 (0.175119) with : {'activation': 'softplus', 'init_mode': 'glorot_normal'}\n",
      "0.420000 (0.244586) with : {'activation': 'softplus', 'init_mode': 'glorot_uniform'}\n",
      "0.333333 (0.069921) with : {'activation': 'softplus', 'init_mode': 'he_normal'}\n",
      "0.346667 (0.095685) with : {'activation': 'softplus', 'init_mode': 'he_uniform'}\n",
      "0.386667 (0.205047) with : {'activation': 'softsign', 'init_mode': 'uniform'}\n",
      "0.273333 (0.169181) with : {'activation': 'softsign', 'init_mode': 'lecun_uniform'}\n",
      "0.246667 (0.040000) with : {'activation': 'softsign', 'init_mode': 'normal'}\n",
      "0.440000 (0.138884) with : {'activation': 'softsign', 'init_mode': 'zero'}\n",
      "0.400000 (0.156347) with : {'activation': 'softsign', 'init_mode': 'glorot_normal'}\n",
      "0.386667 (0.184511) with : {'activation': 'softsign', 'init_mode': 'glorot_uniform'}\n",
      "0.373333 (0.205913) with : {'activation': 'softsign', 'init_mode': 'he_normal'}\n",
      "0.326667 (0.200444) with : {'activation': 'softsign', 'init_mode': 'he_uniform'}\n",
      "nan (nan) with : {'activation': ' relu', 'init_mode': 'uniform'}\n",
      "nan (nan) with : {'activation': ' relu', 'init_mode': 'lecun_uniform'}\n",
      "nan (nan) with : {'activation': ' relu', 'init_mode': 'normal'}\n",
      "nan (nan) with : {'activation': ' relu', 'init_mode': 'zero'}\n",
      "nan (nan) with : {'activation': ' relu', 'init_mode': 'glorot_normal'}\n",
      "nan (nan) with : {'activation': ' relu', 'init_mode': 'glorot_uniform'}\n",
      "nan (nan) with : {'activation': ' relu', 'init_mode': 'he_normal'}\n",
      "nan (nan) with : {'activation': ' relu', 'init_mode': 'he_uniform'}\n",
      "0.286667 (0.033993) with : {'activation': 'tanh', 'init_mode': 'uniform'}\n",
      "0.380000 (0.085894) with : {'activation': 'tanh', 'init_mode': 'lecun_uniform'}\n",
      "0.413333 (0.104563) with : {'activation': 'tanh', 'init_mode': 'normal'}\n",
      "0.353333 (0.157198) with : {'activation': 'tanh', 'init_mode': 'zero'}\n",
      "0.386667 (0.108730) with : {'activation': 'tanh', 'init_mode': 'glorot_normal'}\n",
      "0.360000 (0.082731) with : {'activation': 'tanh', 'init_mode': 'glorot_uniform'}\n",
      "0.480000 (0.054160) with : {'activation': 'tanh', 'init_mode': 'he_normal'}\n",
      "0.300000 (0.101105) with : {'activation': 'tanh', 'init_mode': 'he_uniform'}\n",
      "0.273333 (0.074237) with : {'activation': 'sigmoid', 'init_mode': 'uniform'}\n",
      "0.393333 (0.112349) with : {'activation': 'sigmoid', 'init_mode': 'lecun_uniform'}\n",
      "0.393333 (0.104137) with : {'activation': 'sigmoid', 'init_mode': 'normal'}\n",
      "0.366667 (0.117379) with : {'activation': 'sigmoid', 'init_mode': 'zero'}\n",
      "0.280000 (0.137598) with : {'activation': 'sigmoid', 'init_mode': 'glorot_normal'}\n",
      "0.313333 (0.049889) with : {'activation': 'sigmoid', 'init_mode': 'glorot_uniform'}\n",
      "0.326667 (0.092856) with : {'activation': 'sigmoid', 'init_mode': 'he_normal'}\n",
      "0.340000 (0.080000) with : {'activation': 'sigmoid', 'init_mode': 'he_uniform'}\n",
      "0.306667 (0.110353) with : {'activation': 'hard_sigmoid', 'init_mode': 'uniform'}\n",
      "0.360000 (0.173077) with : {'activation': 'hard_sigmoid', 'init_mode': 'lecun_uniform'}\n",
      "0.380000 (0.106667) with : {'activation': 'hard_sigmoid', 'init_mode': 'normal'}\n",
      "0.333333 (0.203306) with : {'activation': 'hard_sigmoid', 'init_mode': 'zero'}\n",
      "0.326667 (0.108321) with : {'activation': 'hard_sigmoid', 'init_mode': 'glorot_normal'}\n",
      "0.353333 (0.152898) with : {'activation': 'hard_sigmoid', 'init_mode': 'glorot_uniform'}\n",
      "0.320000 (0.106667) with : {'activation': 'hard_sigmoid', 'init_mode': 'he_normal'}\n",
      "0.280000 (0.033993) with : {'activation': 'hard_sigmoid', 'init_mode': 'he_uniform'}\n",
      "0.366667 (0.168655) with : {'activation': 'linear', 'init_mode': 'uniform'}\n",
      "0.286667 (0.207204) with : {'activation': 'linear', 'init_mode': 'lecun_uniform'}\n",
      "0.293333 (0.142049) with : {'activation': 'linear', 'init_mode': 'normal'}\n",
      "0.340000 (0.156915) with : {'activation': 'linear', 'init_mode': 'zero'}\n",
      "0.266667 (0.147573) with : {'activation': 'linear', 'init_mode': 'glorot_normal'}\n",
      "0.440000 (0.110353) with : {'activation': 'linear', 'init_mode': 'glorot_uniform'}\n",
      "0.320000 (0.108730) with : {'activation': 'linear', 'init_mode': 'he_normal'}\n",
      "0.333333 (0.169967) with : {'activation': 'linear', 'init_mode': 'he_uniform'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = dict(init_mode = init_mode, activation = activation)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X,y)\n",
    "print(\"스코어: %f 사용한 조합: %s\" %(grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with : %r\" %(mean,stdev,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 조합은 {'activation': 'tanh', 'init_mode': 'he_normal'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 epochs, batchsize 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim = 4, activation='tanh'))\n",
    "    model.add(Dense(3, kernel_initializer = 'he_normal', activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "model = KerasClassifier(build_fn = create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스코어: 0.980000 사용한 조합: {'batch_size': 10, 'epochs': 100}\n",
      "0.606667 (0.159722) with : {'batch_size': 10, 'epochs': 10}\n",
      "0.926667 (0.057349) with : {'batch_size': 10, 'epochs': 50}\n",
      "0.980000 (0.016330) with : {'batch_size': 10, 'epochs': 100}\n",
      "0.466667 (0.150555) with : {'batch_size': 20, 'epochs': 10}\n",
      "0.940000 (0.024944) with : {'batch_size': 20, 'epochs': 50}\n",
      "0.933333 (0.021082) with : {'batch_size': 20, 'epochs': 100}\n",
      "0.560000 (0.248909) with : {'batch_size': 40, 'epochs': 10}\n",
      "0.800000 (0.138243) with : {'batch_size': 40, 'epochs': 50}\n",
      "0.886667 (0.080554) with : {'batch_size': 40, 'epochs': 100}\n",
      "0.360000 (0.099778) with : {'batch_size': 60, 'epochs': 10}\n",
      "0.633333 (0.069921) with : {'batch_size': 60, 'epochs': 50}\n",
      "0.780000 (0.154344) with : {'batch_size': 60, 'epochs': 100}\n",
      "0.393333 (0.187853) with : {'batch_size': 80, 'epochs': 10}\n",
      "0.793333 (0.099778) with : {'batch_size': 80, 'epochs': 50}\n",
      "0.780000 (0.165462) with : {'batch_size': 80, 'epochs': 100}\n",
      "0.333333 (0.189737) with : {'batch_size': 100, 'epochs': 10}\n",
      "0.720000 (0.275358) with : {'batch_size': 100, 'epochs': 50}\n",
      "0.846667 (0.065320) with : {'batch_size': 100, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "batch_size = [10,20,40,60,80,100]\n",
    "epochs = [10,50,100]\n",
    "\n",
    "param_grid = dict(batch_size = batch_size, epochs = epochs) # compile에서 수행하는 일\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs =-1 )\n",
    "grid_result = grid.fit(X,y)\n",
    "print(\"스코어: %f 사용한 조합: %s\"%(grid_result.best_score_, grid_result.best_params_))\n",
    "mean = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(mean, stds, params):\n",
    "    print(\"%f (%f) with : %r\" %(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 조합은 {'batch_size': 10, 'epochs': 100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipeline사용해 얼마나 정확하게 분류되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 1.3137 - accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 1.0965 - accuracy: 0.3733\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.9651 - accuracy: 0.5933\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.8748 - accuracy: 0.5467\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.7992 - accuracy: 0.6867\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.7403 - accuracy: 0.7733\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.6952 - accuracy: 0.8333\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.6603 - accuracy: 0.8267\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.6303 - accuracy: 0.8467\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.6052 - accuracy: 0.8667\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.5824 - accuracy: 0.8733\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.5600 - accuracy: 0.8667\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.5418 - accuracy: 0.8867\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.5222 - accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.5039 - accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.4911 - accuracy: 0.9133\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.4753 - accuracy: 0.9267\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.4609 - accuracy: 0.9467\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.4489 - accuracy: 0.9467\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.4373 - accuracy: 0.9667\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.4258 - accuracy: 0.9667\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.4152 - accuracy: 0.9600\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.4058 - accuracy: 0.9667\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.3972 - accuracy: 0.9733\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.3870 - accuracy: 0.9667\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.3794 - accuracy: 0.9600\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 0s 67us/step - loss: 0.3698 - accuracy: 0.9667\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.3634 - accuracy: 0.9667\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.3550 - accuracy: 0.9733\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.3472 - accuracy: 0.9667\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.3397 - accuracy: 0.9733\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.3334 - accuracy: 0.9667\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.3254 - accuracy: 0.9667\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.3194 - accuracy: 0.9733\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.3119 - accuracy: 0.9733\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.3068 - accuracy: 0.9733\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.3041 - accuracy: 0.9667\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2938 - accuracy: 0.9733\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2951 - accuracy: 0.9667\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2824 - accuracy: 0.9667\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.2781 - accuracy: 0.9733\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2719 - accuracy: 0.9733\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2684 - accuracy: 0.9733\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2611 - accuracy: 0.9800\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.2575 - accuracy: 0.9667\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2525 - accuracy: 0.9667\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2470 - accuracy: 0.9733\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.2431 - accuracy: 0.9600\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2384 - accuracy: 0.9667\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2338 - accuracy: 0.9733\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.2300 - accuracy: 0.9667\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.2282 - accuracy: 0.9800\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2230 - accuracy: 0.9600\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2176 - accuracy: 0.9667\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2135 - accuracy: 0.9733\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2106 - accuracy: 0.9667\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2065 - accuracy: 0.9667\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 0s 80us/step - loss: 0.2068 - accuracy: 0.9667\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.2020 - accuracy: 0.9667\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.1988 - accuracy: 0.9667\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.1942 - accuracy: 0.9667\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.1914 - accuracy: 0.9667\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1872 - accuracy: 0.9667\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1871 - accuracy: 0.9667\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1829 - accuracy: 0.9667\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1790 - accuracy: 0.9733\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1769 - accuracy: 0.9733\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1730 - accuracy: 0.9667\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1712 - accuracy: 0.9667\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1709 - accuracy: 0.9800\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1651 - accuracy: 0.9733\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1638 - accuracy: 0.9667\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.1622 - accuracy: 0.9667\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1594 - accuracy: 0.9667\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1588 - accuracy: 0.9667\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1547 - accuracy: 0.9667\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1531 - accuracy: 0.9667\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1520 - accuracy: 0.9667\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1492 - accuracy: 0.9667\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 53us/step - loss: 0.1468 - accuracy: 0.9667\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1482 - accuracy: 0.9733\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1488 - accuracy: 0.9733\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.1424 - accuracy: 0.9733\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 0s 66us/step - loss: 0.1420 - accuracy: 0.9667\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.1385 - accuracy: 0.9733\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1369 - accuracy: 0.9667\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1355 - accuracy: 0.9667\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1354 - accuracy: 0.9733\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1335 - accuracy: 0.9733\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1309 - accuracy: 0.9800\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1302 - accuracy: 0.9733\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1283 - accuracy: 0.9667\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1295 - accuracy: 0.9733\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1247 - accuracy: 0.9733\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 0s 73us/step - loss: 0.1242 - accuracy: 0.9733\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.1220 - accuracy: 0.9667\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1222 - accuracy: 0.9733\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1205 - accuracy: 0.9733\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 0s 53us/step - loss: 0.1196 - accuracy: 0.9733\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 0s 60us/step - loss: 0.1212 - accuracy: 0.9733\n",
      "150/150 [==============================] - 0s 339us/step\n",
      "\n",
      "Accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, input_dim=4, activation='tanh'))\n",
    "model.add(Dense(3, kernel_initializer ='he_normal' ,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=100, batch_size=10)\n",
    "\n",
    "print('\\nAccuracy: {:.4f}'.format(model.evaluate(X, y)[1]))\n",
    "# 정확도 0.9733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=4, activation='tanh'))\n",
    "    model.add(Dense(3, kernel_initializer ='he_normal' ,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "estimator = KerasClassifier(build_fn = best_model, nb_epoch=100, batch_size = 10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 0.30 (0.18) MSE\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits = 10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, y, cv = kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(),results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.2       , 0.53333336, 0.26666668, 0.53333336,\n",
       "       0.26666668, 0.2       , 0.06666667, 0.46666667, 0.46666667])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ICT01_21\\Anaconda3\\envs\\tf_test\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: 0.96 (0.04 MSE)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('stanardize', StandardScaler()))\n",
    "estimators.append(('mip', KerasClassifier(build_fn=best_model, epochs = 50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators) # train, test 데이터의 전처리를 한번에 할 수 있도록 도와줌\n",
    "kfold = KFold(n_splits = 10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv = kfold)\n",
    "print(\"Standardized: %.2f (%.2f MSE)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('stanardize',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('mip',\n",
       "                 <keras.wrappers.scikit_learn.KerasClassifier object at 0x0000021AB0FA67C8>)],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pipeline.predict(X)\n",
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
